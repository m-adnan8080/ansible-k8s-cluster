# View kubeconfig
kubectl config view

# View the current context for kubectl
kubectl config current-context

# Change context
kubectl config use-context cluster-1

# Get nodes status
kubectl get nodes

# Label nodes
kubectl label node worker1 node-role.kubernetes.io/worker=worker

# Taint a node and remove taint from node
kubectl taint node <node_name> key=value:taint-effect
kubectl taint node node-01 app=frontend:[NoSchedule|NoExecute|PreferNoSchedule]
kubectl taint node node-01 app=frontend:NoSchedule
kubectl taint node node-01 app=frontend:NoSchedule-

# Get pod status
kubectl get pod

# Get services status
kubectl get services

# Create deployment of specific container / service from docker hub
kubectl create deployment [deployment-name] --image=[container-name]
kubectl create deployment nginx-web --image=nginx:alpine

# Get deployment status
kubectl get deployment

# Get the replica set
kubectl get replicaset

# Edit the auto-generated config file having default values of the deployment
kubectl edit deployment <deployment-name>
kubectl edit deployment nginx-web

# Pod / container debugging
# Check the logs of a pod
kubectl logs nginx-web-234dw344d234-fdexx

# Get status of pods short details and log details
kubectl get pods label=nginx-web
kubectl get pods label=nginx-web -o wide

# Get detail information about pod
kubectl describe pod [pod-name]

# Enter pod / container with interactive shell for debugging
kubectl exec -it [pod-name] -- /bin/bash

# Access deployment pad from outside kubernetes
# Create service to use nodes port for access
kubectl create service nodeport nginx-service --tcp=80:80

# Get status of service
kubectl get service <service-name>
kubectl get service nginx-service

# To veiw or save running deployment or service in yaml format
kubectl get deploy <deployment-name> -o yaml
kubectl get service <service-name> -o yaml
kubectl get deploy <deployment-name> -o yaml > deployment.yaml
kubectl get service <service-name> -o yaml > service.yaml

# Remove deployment or service
kubectl delete deployment [deployment-name]
kubectl delete deployment nginx-web
kubectl delete service [service-name]
kubectl delete service nginx-service

# Create or delete deployment/service from yaml file
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
kubectl delete -f deployment.yaml
kubectl delete -f service.yaml

# Fix DNS resolution in Kubernetes Cluster
==========================================
kubectl create -f https://k8s.io/examples/admin/dns/busybox.yaml
kubectl get pods busybox
kubectl exec -ti busybox -- nslookup kubernetes.default
kubectl exec -ti busybox -- nslookup google.com

# if facing dns issue run on both master and worker nodes
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X

# if problem still persists then recreate the dns pods
kubectl get pod -n kube-system  -l k8s-app=kube-dns
kubectl delete pod -n kube-system  -l k8s-app=kube-dns

# Verify dns working
kubectl exec -ti busybox -- nslookup google.com

# if issue solved then remove busybox
kubectl delete -f https://k8s.io/examples/admin/dns/busybox.yaml

# Deploy Kubernetes dashbaord
=============================
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml --dry-run=client -o yaml > dashboard-deploy.yaml

kubectl apply -f dashboard-deploy.yaml

# Create service account and cluster role binding to access dashbaord
# nano dashboard-user.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard

kubectl apply -f dashboard-user.yaml

# Get token
kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath="{.secrets[0].name}") -o go-template="{{.data.token | base64decode}}"; echo ""

# Proxy kubernetes dashboard
kubectl proxy --address 0.0.0.0 --accept-hosts '.*' &

=====================
# If facing issue access the dashboard then you need to create p12 certifacte file from crt and key files from kubeconfig. Then import p12 certificate file to local browser.

### kubecfg.crt
grep 'client-certificate-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt&gt kubecfg.crt

### kubecfg.key
grep 'client-key-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt kubecfg.key

### kubecfg.p12
openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name "kubernetes-client"
=====================

# Access dashboard from URL
http://server-ip:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/

# Create secret for treescale.com docker repo
kubectl create secret docker-registry treescale-reg-cred --docker-server='https://repo.treescale.com' --docker-username='adnan80' --docker-password='ea1efc7a03d1443f9a1f4d15897eca6d' --docker-email='m.adnan80@gmail.com'

# or using docker config.json file
kubectl create secret docker-registry regcred --from-file=".dockerconfigjson=/home/khanaadn/.docker/config.json"

# YAML file syntax, consists of mainly three portions
# while first two lines what you want to create
# 1. Metadata
# 2. Specification
# 3. Status

# Sample YAML file to create Deployment
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  label: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:tag
        ports:
        - containerPort: 80
status: {}

# Sample YAML file to create Service
---
apiVersion: apps/v1
kind: Service
metadata:
  name: nginx
  label: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:tag
        ports:
        - containerPort: 80
status: {}

==========================================================
Pulling out kubelet-dynamic-config from kubernetes cluster
==========================================================
kubectl proxy --port=8001 &

NODE_NAME="the-name-of-the-node-you-are-reconfiguring"
curl -sSL "http://localhost:8001/api/v1/nodes/${NODE_NAME}/proxy/configz" | jq '.kubeletconfig|.kind="KubeletConfiguration"|.apiVersion="kubelet.config.k8s.io/v1beta1"' > kubelet-dynamic-config

==========================================================
kubectl create deployment aspnetapp --image=mcr.microsoft.com/dotnet/samples:aspnetapp
kubectl expose deployment aspnetapp --port 80
kubectl edit service aspnetapp
# change ClusterIP to NodePort

sudo apt install siege -y
sudo siege 192.168.42.216

# To run the test for 40 seconds, use the format below default concurrency is 25:
sudo siege -t40S http://192.168.42.216

# To run the test for 30 concurrent users, use the format below:
sudo siege -c30 http://192.168.42.216

# To run the test for 40 seconds and 30 concurrent users, use the format below:
sudo siege -t40S -c30 192.168.42.216


=======================
Install kube-vip
(Kubernetes Control Plane Virtual IP and Load-Balancer)
=======================
# Download kube-vip rbac.yaml
curl -s https://kube-vip.io/manifests/rbac.yaml > /var/lib/rancher/k3s/server/manifests/kube-vip-rbac.yaml

# Add below lines to rules under rbac.authorization.k8s.io/v1

  - apiGroups: ["coordination.k8s.io"]
    resources: ["lease"]
    verbs: ["list", "get", "watch", "update", "create"]

# Download kube-vip docker images
crictl pull docker.io/plndr/kube-vip:0.3.2
#docker pull docker.io/plndr/kube-vip:0.3.2

# Create alias
alias kube-vip="crt run --rm --net-host docker.io/plndr/kube-vip:0.3.2 vip /kube-vip"
#alias kube-vip="docker run --rm --net-host docker.io/plndr/kube-vip:0.3.2 vip /kube-vip"

export $INTERFACE=eth0
export $VIP=192.168.122.10

kube-vip manifests deamonset --arp --inteface $INTERFACE --address $VIP --controlplane --leaderElection --taint --inCluster | tee /var/lib/rancher/k3s/server/manifests/kube-vip.yaml


# Add below line in the kube-vip.yaml under tolerations block
      operator: Exists

# Edit server ip address to vip-ip in kubeconfig

# Deploy metrics-server in k8s cluster
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml